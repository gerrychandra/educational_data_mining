{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file of this notebook is the transformed data from previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"../data/processed/data_model_noss.pkl\"\n",
    "out_model_path = \"../model/\"\n",
    "out_eval_path = \"../data/evaluation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname\n",
    "import os, sys, inspect\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "parentdir = dirname(currentdir)\n",
    "\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs\n",
    "Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from src.utils import dump_to_pickle\n",
    "from src.evaluate import create_eval_df, plot_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_eng</th>\n",
       "      <th>hs_math</th>\n",
       "      <th>hs_bio</th>\n",
       "      <th>hs_chem</th>\n",
       "      <th>hs_phy</th>\n",
       "      <th>hs_econ</th>\n",
       "      <th>hs_geo</th>\n",
       "      <th>hs_soc</th>\n",
       "      <th>hs_final</th>\n",
       "      <th>major_name</th>\n",
       "      <th>school_prop</th>\n",
       "      <th>school_geo_unit</th>\n",
       "      <th>school_state</th>\n",
       "      <th>faculty</th>\n",
       "      <th>fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>73.25</td>\n",
       "      <td>70.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.50</td>\n",
       "      <td>73.75</td>\n",
       "      <td>79.25</td>\n",
       "      <td>30.80</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>77.75</td>\n",
       "      <td>64.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.25</td>\n",
       "      <td>80.00</td>\n",
       "      <td>76.25</td>\n",
       "      <td>25.95</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70.25</td>\n",
       "      <td>66.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.50</td>\n",
       "      <td>77.50</td>\n",
       "      <td>82.25</td>\n",
       "      <td>27.40</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>82.25</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.75</td>\n",
       "      <td>77.75</td>\n",
       "      <td>72.75</td>\n",
       "      <td>28.40</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85.25</td>\n",
       "      <td>78.00</td>\n",
       "      <td>80.25</td>\n",
       "      <td>75.5</td>\n",
       "      <td>78.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.90</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hs_eng  hs_math  hs_bio  hs_chem  hs_phy  hs_econ  hs_geo  hs_soc  \\\n",
       "0   73.25    70.75    0.00      0.0     0.0    86.50   73.75   79.25   \n",
       "1   77.75    64.75    0.00      0.0     0.0    79.25   80.00   76.25   \n",
       "2   70.25    66.75    0.00      0.0     0.0    79.50   77.50   82.25   \n",
       "3   82.25    85.00    0.00      0.0     0.0    71.75   77.75   72.75   \n",
       "4   85.25    78.00   80.25     75.5    78.5     0.00    0.00    0.00   \n",
       "\n",
       "   hs_final  major_name  school_prop  school_geo_unit  school_state  faculty  \\\n",
       "0     30.80          14            4                6            33        0   \n",
       "1     25.95          14            4                0             7        0   \n",
       "2     27.40          14            4                7            21        0   \n",
       "3     28.40          14            4                0             9        0   \n",
       "4     33.90          14            5                5            27        0   \n",
       "\n",
       "   fail  \n",
       "0     0  \n",
       "1     1  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity in the front-end, we minimize the amount of data that user needs to input. So school features are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['school_prop',\n",
    "                  'school_geo_unit',\n",
    "                  'school_state',\n",
    "                  'faculty'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "The data is splitted 67% for train set and the rest 33% for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('fail', axis=1)\n",
    "y = data['fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:  1407\n",
      "Test Size:  694\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Size: \", X_train.shape[0])\n",
    "print(\"Test Size: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalance Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class size is very imbalanced (label 0: label 1 = 90:10). We use over-sampling technique to deal with this problem. `SMOTE` is used to upsample the train set so that the proportion between negative class and positive class is roughly 50:50 (balanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.900498\n",
       "1    0.099502\n",
       "Name: fail, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ratio = 0.5\n",
    "\n",
    "sm = SMOTE(random_state=187,\n",
    "           ratio={\n",
    "               0:y_train.value_counts()[0],\n",
    "               1:int(y_train.value_counts()[0]*(target_ratio/(1-target_ratio)))\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_upsampled, y_train_upsampled = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train_upsampled)/len(y_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After everything is ready, the data is then trained using 3 different classifiers. The trained data is used to predict both train set and test set and the result is then saved to be evaluated later.\n",
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(random_state=100).fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "#save model\n",
    "dump_to_pickle(log_model, out_model_path+'log_model_noss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_pred = log_model.predict_proba(X_train)\n",
    "log_test_pred = log_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_eval_train, log_eval_test, log_eval_data = create_eval_df(log_train_pred, log_test_pred, y_train, y_test)\n",
    "\n",
    "#save eval data\n",
    "log_save_objs = log_eval_data, log_eval_train, log_eval_test\n",
    "dump_to_pickle(log_save_objs, out_eval_path+'log_eval_noss.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(max_depth=3, random_state=100).fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "#save model\n",
    "dump_to_pickle(RF_model, out_model_path+'RF_model_noss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_train_pred = RF_model.predict_proba(X_train)\n",
    "RF_test_pred = RF_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_eval_train, RF_eval_test, RF_eval_data = create_eval_df(RF_train_pred, RF_test_pred, y_train, y_test)\n",
    "\n",
    "#save eval data\n",
    "RF_save_objs = RF_eval_data, RF_eval_train, RF_eval_test\n",
    "dump_to_pickle(RF_save_objs, out_eval_path+'RF_eval_noss.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(probability=True, random_state=100).fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "#save model\n",
    "dump_to_pickle(SVC_model, out_model_path+'SVC_model_noss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_train_pred = SVC_model.predict_proba(X_train)\n",
    "SVC_test_pred = SVC_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_eval_train, SVC_eval_test, SVC_eval_data = create_eval_df(SVC_train_pred, SVC_test_pred, y_train, y_test)\n",
    "\n",
    "#save eval data\n",
    "SVC_save_objs = SVC_eval_data, SVC_eval_train, SVC_eval_test\n",
    "dump_to_pickle(SVC_save_objs, out_eval_path+'SVC_eval_noss.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
